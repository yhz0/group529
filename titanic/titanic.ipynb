{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISE 529 HW 5\n",
    "## Session: W\n",
    "## Group Members: Naichang LU, Feiyang GU, Qikai GAO, Yihang ZHANG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "5767a33c-8f18-4034-e52d-bf7a8f7d8ab8",
    "_uuid": "847a9b3972a6be2d2f3346ff01fea976d92ecdb6"
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import metrics, model_selection, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5767a33c-8f18-4034-e52d-bf7a8f7d8ab8",
    "_uuid": "847a9b3972a6be2d2f3346ff01fea976d92ecdb6"
   },
   "outputs": [],
   "source": [
    "# set random seed to 1 so that this produces result that is repeatable.\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "5767a33c-8f18-4034-e52d-bf7a8f7d8ab8",
    "_uuid": "847a9b3972a6be2d2f3346ff01fea976d92ecdb6"
   },
   "outputs": [],
   "source": [
    "# Generating data as required\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "train_df.shape, test_df.shape\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "guess_ages = np.zeros((2,3))\n",
    "guess_ages\n",
    "\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n",
    "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n",
    "\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age']                          = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n",
    "    # np.piecewise() # this author is stupid\n",
    "\n",
    "train_df = train_df.drop(['AgeBand'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
    "\n",
    "freq_port = train_df.Embarked.dropna().mode()[0]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n",
    "\n",
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_df = train_df.drop(['FareBand'], axis=1)\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "5767a33c-8f18-4034-e52d-bf7a8f7d8ab8",
    "_uuid": "847a9b3972a6be2d2f3346ff01fea976d92ecdb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 8), (891,), (418, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors\n",
    "\n",
    "- Pclass\n",
    "    - (categorical) Passenger class\n",
    "- Sex\n",
    "    - (binary) 1 if female, 0 if male\n",
    "- Age\n",
    "    - (categorical) Age group\n",
    "- Fare\n",
    "    - (categorical) Fare group\n",
    "- Embarked\n",
    "    - (categorical) The port which the passenger embarked\n",
    "- IsAlone\n",
    "    - (binary) 1 if alone, else 0\n",
    "- Age * Class\n",
    "    - (Numeric) Age group * Passenger class group (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
       "0       3    0    1     0         0      1        0          3\n",
       "1       1    1    2     3         1      3        0          2\n",
       "2       3    1    1     1         0      2        1          3\n",
       "3       1    1    2     3         0      3        0          2\n",
       "4       3    0    2     1         0      1        1          6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 18) (418, 18)\n"
     ]
    }
   ],
   "source": [
    "# Certain classifiers works better with one-hot encoded variables.\n",
    "# Let's do one hot encoding.\n",
    "dummy_columns = [\"Pclass\", \"Age\", \"Fare\", \"Embarked\", \"Title\"]\n",
    "n_train = len(X_train)\n",
    "combine = pd.concat([X_train, X_test])\n",
    "combine.shape\n",
    "combine_dummy = pd.get_dummies(combine, columns=dummy_columns, drop_first=True)\n",
    "X_train_dummy = combine_dummy[:n_train]\n",
    "X_test_dummy = combine_dummy[n_train:]\n",
    "print(X_train_dummy.shape, X_test_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function\n",
    "# Takes a model and get the 5-fold cross validation\n",
    "# score under specified metric\n",
    "def getScore(model, X_train, Y_train, metric=metrics.accuracy_score):\n",
    "    cv = model_selection.KFold(n_splits=5, random_state=1)\n",
    "    score = model_selection.cross_val_score(model,\n",
    "            X_train,Y_train,scoring=metrics.make_scorer(metric), cv=cv)\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.803616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.802498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.802479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.800207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.793516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.780083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.705932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.695838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.641190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy rate\n",
       "0                Random Forest       0.803616\n",
       "8                   Linear SVC       0.802498\n",
       "4          Logistic Regression       0.802479\n",
       "2      Support Vector Machines       0.800207\n",
       "1                Decision Tree       0.793516\n",
       "3                          KNN       0.780083\n",
       "7  Stochastic Gradient Descent       0.705932\n",
       "5                  Naive Bayes       0.695838\n",
       "6                   Perceptron       0.641190"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the classifiers that requires one-hot encoding.\n",
    "# Notice that we add random_state=1 to classifiers that either:\n",
    "# whose model depends on random state; or\n",
    "# optimization of the model depends on stochastic methods.\n",
    "model_dict_dummy = {\n",
    "    'Support Vector Machines':SVC(gamma='auto', random_state=1),\n",
    "    'KNN':KNeighborsClassifier(n_neighbors = 3),\n",
    "    'Logistic Regression':LogisticRegression(solver='lbfgs', random_state=1),\n",
    "    'Naive Bayes':GaussianNB(),\n",
    "    'Perceptron':Perceptron(),\n",
    "    'Stochastic Gradient Descent':SGDClassifier(random_state=1),\n",
    "    'Linear SVC':LinearSVC(max_iter=10000, random_state=1)\n",
    "}\n",
    "\n",
    "# These are the classifiers that requires one-hot encoding.\n",
    "model_dict = {\n",
    "     'Random Forest':RandomForestClassifier(n_estimators=100, random_state=1),\n",
    "     'Decision Tree':DecisionTreeClassifier(random_state=1)\n",
    "}\n",
    "\n",
    "model_name = list(model_dict.keys())\n",
    "model_dummy_name = list(model_dict_dummy.keys())\n",
    "\n",
    "score_list = (\n",
    "    [getScore(model_dict[n],X_train,Y_train) for n in model_name]\n",
    "    + [getScore(model_dict_dummy[n] ,X_train_dummy,Y_train)\n",
    "       for n in model_dummy_name]\n",
    ")\n",
    "\n",
    "score_pd = pd.DataFrame({'model': model_name + model_dummy_name,'Accuracy rate':score_list}) \n",
    "score_pd.sort_values(by='Accuracy rate', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a grid search and to find the optimal set of hyperparameters for XGBoost\n",
    "cv = model_selection.KFold(n_splits=5)\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": np.arange(50, 1001, 50),\n",
    "    \"max_depth\": np.arange(2, 10)\n",
    "}\n",
    "xgb = model_selection.GridSearchCV(XGBClassifier(random_state=1, silent=True),\n",
    "    xgb_param_grid, cv=cv, scoring=\"accuracy\", return_train_score=True, n_jobs=-1)\n",
    "xgb.fit(X_train, Y_train)\n",
    "xgb_best_param = xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835820895522388"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the hyperparameters obtained above, we fit a new XGBoost model.\n",
    "X_tr, X_te, Y_tr, Y_te = model_selection.train_test_split(\n",
    "    X_train, Y_train, test_size=0.3, random_state=1\n",
    ")\n",
    "xgb = XGBClassifier(n_estimators=xgb_best_param[\"n_estimators\"],\n",
    "    max_depth=xgb_best_param[\"max_depth\"]\n",
    ").fit(X_tr, Y_tr)\n",
    "pred = xgb.predict(X_te)\n",
    "xgb.score(X_te,Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8254617789144645\n"
     ]
    }
   ],
   "source": [
    "# AUC Metric\n",
    "pred_proba = xgb.predict_proba(X_te)\n",
    "auc = metrics.roc_auc_score(Y_te,pred_proba[:,1])\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xUVfrH8c9JI5BCLxJCQGpChwjSiaGjBAUpEQiBAIosLljZ5upafiiW1aVKEJdVWUWlaBQWKQGkhRIggVCCaQgESGjpmfP7IzFEDGQISe6U5/168WLKmZmHQ+bL5dx7n6u01gghhLB9DkYXIIQQonJI4AshhJ2QwBdCCDshgS+EEHZCAl8IIeyEBL4QQtiJUgNfKbVcKXVBKXX0Ns8rpdQHSqlTSqnDSqnO5V+mEEKIe2XOFv4KYPAdnh8CtCj8NQ1YdO9lCSGEKG+lBr7WOhK4fIchQcC/dYHdQA2l1H3lVaAQQojy4VQO7+EFJBW7n1z42C+3DlRKTaPgfwG4ubl1ad26dTl8vBBCWCcNXM3M5dL1bG7k5N9xbN6VC5iyb4Ap/6LWum5ZPq88Al+V8FiJ/Rq01kuBpQD+/v46KiqqHD5eCCHKLiMnj59OXeLo2StUZqeZrNx81kefJfdKFm1qVSWkexMGtWmAk+PNSP219Y1Sik/Cl3IxNZV3/u/1hLJ+ZnkEfjLgXex+I+BsObyvEEKUO6018RdvsDUula1xF9gTf5mcfJMhtXS/vzZ/H96GQN/6ODr8dts5JSWFp556ijFjxvDEE0/w0pxnAHjn/14v8+eVR+CvA2YqpVYB3YArWuvfLecIIYRRsnLz2RV/ia3HL7AlLpXEyxkANK/nTkgPHwJa1cO/SS1cnIw/Ul1rzbJly3juuefIzc1l2LBh5fbepQa+UupzoB9QRymVDLwMOBcWthiIAIYCp4AMILTcqhNCiDJKuFSwFb8l7gK7Tl8iO8+Eq7MDPZvVYWqf++nXsi7etaoZXeZvnD59mqlTp7JlyxYCAgL46KOPaNasWbm9f6mBr7UeV8rzGni63CoSQogSZObks+ZQCv+LPU+e6c6L7cmXM4i/eAOApnXcCO7WmIBW9ejatBauzo6VUW6ZHDlyhP3797N06VLCwsJQqqRdpGVXHks6QghRYc6mZ7JydwKf700kPSOXpnXcqF7V+Y6v8aldjYndfejXqh5N6rhVUqVlc/ToUQ4cOMDEiRMZMWIE8fHx1K5du0I+SwJfCGFxtNZEJaSxYufP/BBzDq01A/0aENqzCV2b1ir3LV8j5OTk8MYbb/DGG29Qv359Ro8ejaura4WFPUjgCyEsSHZePuujf2HFT2c4mnIVT1cnwno1ZfyDPha33n4v9uzZw5QpU4iJiWH8+PG89957uLq6VvjnSuALISpNVm4+f/7mKBtjz5X4fE6eiew8E83rufPaiLY81tmLai62FVMpKSn07t2b+vXr8+2335brUTilsa2ZFEJYjOy8fPLyb+5cvZqVy8zPDrI/IY2RnRvhWfX38eOgFP1a1aVX8zo2sWxT3IkTJ2jZsiVeXl7897//JTAwEE9Pz0qtQQJfCFHuktMyCHxnG9l5vz2hqYqTAwuf6MzQdvbTbis9PZ0XXniBZcuWsXXrVvr06cOjjz5qSC0S+EKIcqO1JulyJtHJ6WTnmRjj702zejePkunVvC5+DSt3q9ZI69at46mnnuLcuXM8//zzPPDAA4bWI4EvhCg33x89x4xPDxTdD+rUkB7N6hhYkXHCwsIIDw+nXbt2rF27Fn9/f6NLksAXQtydfJMm9uxVrmTm/u65vWcKOqm/NqItDTxd6da04g4xtETFm535+/vj4+PDiy++iIuLi8GVFZDAF0KUKu1GDpEnU9ly/ALbTqSSlvH7sP+Vo4NieMeGeLre+eQoW5OUlMSTTz7J2LFjmTBhAk8++aTRJf2OBL4QduRqVi4/HjuPuc0hz6ZnsjXuAoeS0jFpqO3mQkCrevRtVZeGNaqW+Jrabi52FfYmk4klS5bw4osvkp+fb9gOWXNI4AthR/67N4nXI46ZPV4paN+oBrMCWxDQqh7tvKrj4GBbh0vei5MnTxIWFkZkZCT9+/dn6dKlNG3a1OiybksCXwg78mvf9x+f7YuLY+mtgD1cnahRzTLWny1RbGwshw8fZvny5UyaNMnizx2QwBfCDnnXrGYRvd+tUXR0NIcOHSIkJISgoCDi4+OpWbOm0WWZRf7GhRDCDNnZ2fz1r3/F39+fv/71r2RlZQFYTdiDBL4QQpRq165ddOrUiddee43g4GAOHjxYKc3Oypss6QghxB2kpKTQt29fGjRoQEREBEOGDDG6pDKTLXwhhCjBsWMFRzN5eXnxxRdfEBMTY9VhDxL4QgjxG2lpaUyePBk/Pz+2b98OwIgRI/Dw8DC4snsnSzpCCFHom2++YcaMGaSmpjJ37lzDm52VNwl8IaxITp6Jq1m5XMvK42pmLlezcrmamce1rJu3C34vHFPssew8Exk5eUb/ESzW5MmT+fjjj+nYsSPfffcdnTt3NrqkcieBL0QlysrNvxnURaF9M7yv3fGxXLJy79wTwUGBZ1VnPF2d8XB1wtPVmSZ1quHp6kwVZwcUiiZ13OQY/ELFm509+OCDtGjRgueeew5nZ9tsDSGBL0QF01qzK/4SH+/8mR+Pncekbz/W2VHh6epcGNpOeFZ1pmH1qgXhXeyxX8P813D3rOqEh6szbi6OFn+2p6VISEhg+vTpBAcHM3HiRKZNm2Z0SRVOAl+ICpKVm8+agyms+Olnjp+7Ri03F8J630/jWtWKwtvD1ZnqVW+GdxUnBwnsCmYymVi0aBEvvfQSWmsef/xxo0uqNBL4QlSQV9bH8PneJHzv8+StUe0Z3qEhrs6ORpdl1+Li4ggLC2PHjh0MHDiQJUuW0KRJE6PLqjQS+ELco4ycPFKvZXPxeja5xS7affrCDZrXcydiVi/ZarcQcXFxxMTEsGLFCiZOnGh3fy8S+EKUwGTSpGXkkHo9mwtXs7lwLZvUa9lcuJZV+Hs2Fwt/v559+yNfOjeuYXehYmkOHjzIoUOHCA0NZfjw4cTHx1OjRg2jyzKEBL6wG9tPpnLpek7RfY3menY+qdeySb2WxYWr2UUBf/F6Nnkl7F11r+JEXY8q1PWogm9DT/oW3q7n4Uodd5ffHf3SvK57hf+5RMmysrJ49dVXeeutt/Dy8mLcuHG4urrabdiDBL6wExeuZTEhfG+JzykFtd1+De4qtKrvUXS7rocr9TyrUNe94Hm3KvKVsQY7d+5kypQpxMXFERoayjvvvGOVzc7Km/z0CpuXkZPHgYQ0AF4Y3Iohbe8req6aiyO13VxwMuNiIMI6pKSkEBAQgJeXFxs2bGDgwIFGl2QxJPCFTTGZNKdTr3MwKZ1DSekcSkwn7vw18k0apaBDoxo0reNmdJmiAsTGxuLn54eXlxdfffUVAQEBuLvLklpxEvjCql26ns2hpHQOJhYEfHRSOtcKd6J6VHGiY+MazPBtRkfvGnT0rkFt9yoGVyzK2+XLl5kzZw6ffPIJ27Zto0+fPjzyyCNGl2WRJPCF1cjOyyfm7FUOJaYXbsGnkXQ5EwBHB0Wr+h4M79iQjt416NS4BvfXcZcLbtu4r776iqeffppLly7x5z//ma5duxpdkkWTwBcWSWtNwqWMgmWZpHQOJqYR+8vVouPc76vuSkfvGozv5kOnxjVp6+VJNRf5cbYnkyZN4pNPPqFz58788MMPdOzY0eiSLJ58Q4RFuJKRy6HkgjX3Q0lpHEpKJy0jFyjYsdrOqzqTezWlk3cNOnrXpEF1OeLCHhVvdtajRw98fX159tlncXKSKDOHWbOklBoM/BNwBJZprf/vlucbA58ANQrHvKS1jijnWoUN+vHYed78/jinLlwHCg6RbFHPnQF+9enoXZOO3jVoWd9djqIRnDlzhmnTpjF+/HhCQkLsotlZeSs18JVSjsACYACQDOxTSq3TWscWG/YX4Aut9SKllB8QATSpgHqFDVmx8wyvfhtLy/oePD+oFR29a9C+UXU8XG2zNa0om/z8fBYsWMDcuXNxcHDgiSeeMLokq2XOFn5X4JTWOh5AKbUKCAKKB74GPAtvVwfOlmeRwrJprTmYlM7HO39mT/wl7tD99zevuXg9hwF+9fnn2I6y/i5KdOzYMaZMmcKuXbsYMmQIixcvpnHjxkaXZbXM+ZZ5AUnF7icD3W4Z83dgo1LqD4Ab0L+kN1JKTQOmAfKXVoFMJm1W6N6r3HwTPxw9x8c7zxCdfAUPVycG+NanipkdIe+v48bkXk1xlCNpxG2cOnWKuLg4Vq5cyRNPPCF9ie6ROYFf0gzfmifjgBVa63eUUt2BlUqptlrr31yeR2u9FFgK4O/vXxmZZHc2xJzjuS+juZZVeZeyu7+uG/8IasNjnRtJ6wFxz/bv3090dDSTJ0/mkUce4cyZM3h6epb+QlEqc76dyYB3sfuN+P2SzRRgMIDWepdSyhWoA1wojyLt2cXr2WTl5ps19oej53g94hjtvaoT6Fu/gisr0MG7Br2b15Hj3cU9y8zM5JVXXmH+/Pl4e3sTHByMq6urhH05Mifw9wEtlFJNgRRgLBB8y5hEIBBYoZTyBVyB1PIs1N6YTJr5G+NYuPX0Xb1uSNsGvDu6I1Vd5EIbwnpERkYSFhbGyZMnmTJlCvPnz5dmZxWg1MDXWucppWYCGyg45HK51jpGKfUqEKW1Xgc8C3yklJpNwXLPJP3rAbPirmXl5vPcl9F8e/gXRnZuRLf7a5n1Ok9XZwb61ZetbWFVUlJSCAwMxNvbm02bNhEYGGh0STZLGZXL/v7+OioqypDPtmSXb+Qw7d9RRCWkMXdIa6b1uV92VAmbdOTIEdq1awfAt99+S0BAAG5u0tiuNEqp/Vpr/7K8Vs5msSAJl27w2MKdHE65woLgzkzv20zCXticixcvMmHCBNq3b09kZCQADz/8sIR9JZBDKizIvzaf4sK1bD6f2o0uPuYt4whhLbTWfPnll8ycOZO0tDRefvllunW79QhvUZEk8A0UceQXUtIyi+7HnL1KA09XCXthk0JCQli5ciX+/v78+OOPRcs5ovJI4Bvk1IVrzPj0wO8e79OyrgHVCFExijc769u3L+3bt+ePf/yjNDsziMy6Qf67LwknB8WW5/pR082l6PGqZp6lKoSli4+PZ+rUqYwfP57Q0FCmTJlidEl2T3baGiAnz8TXB1II9K2Hd61quFdxKvolbQaEtcvPz+f999+nXbt27Nu3DwcHiRlLIVv4Bth8/DyXbuQw5gHv0gcLYUViY2OZPHkye/bsYdiwYSxevJhGjRoZXZYoJIFvgC+ikqnvWYU+LWS9XtiWM2fOcPr0aT777DPGjh0rhxVbGAl8M+WbNO9vOsGOUxfv+b2ik9J5sm8zuaiHsAn79u3j0KFDTJ06lWHDhhEfH4+Hh4fRZYkSSOCbISMnj1mfH2LTsfP4+9S85z41D7Wuz8TuTcqnOCEMkpGRwd/+9jfee+89fHx8mDBhAq6urhL2FkwC3wwzPj1A5IlUXg1qI0EtBLB161bCwsI4ffo006dPZ968edLszApI4JvhaMoVRnZuJGEvBJCcnMyAAQPw8fFh8+bNBAQEGF2SMJMsIpvJxUmmSti36OhoABo1asTatWs5fPiwhL2VkRQTQtxRamoqwcHBdOzYkW3btgEwdOhQqlWrZnBl4m7Jko4QokRaa1atWsWsWbO4cuUKr7zyCt27dze6LHEPJPCFECWaMGECn376Kd26dSM8PJw2bdoYXZK4RxL4QogiJpMJpRRKKQICAujSpQuzZs3C0VF6PNkCWcM3g1ysUdiDU6dOERgYyMcffwzAlClTmD17toS9DZHAv4OkyxnM+HQ/l27kUNejitHlCFEh8vLymD9/Pu3atePgwYO4uLiU/iJhlWRJpwQ3svNYtPU0S7fH46gUcwa0ZFqf+40uS4hyd/ToUUJDQ4mKiiIoKIiFCxfSsGFDo8sSFUQCvxiTSbPmUArzfjjO+avZjOjYkBeHtOa+6lWNLk2ICpGYmEhCQgKrVq1i9OjR0uzMxkngF0q4dINZqw4RnZROh0bVWfhEF7r41DS6LCHK3Z49e4iOjmbatGkMHTqU+Ph43N3djS5LVAJZwy/02nfHiL9wnXce78A3M3pK2Aubc+PGDebMmUP37t156623yM7OBpCwtyMS+BRcX/Z/secJ7dWUkV0a4SBXnRI2ZvPmzbRv35733nuPJ598kgMHDlClihyIYG9kSQdYGhmPq7MDId19jC5FiHKXnJzMoEGDaNq0Kdu2baNPnz5GlyQMYvdb+OeuZPHNwRRG+3tT2122eITtOHjwIFDQ7Gz9+vVER0dL2Ns5uw/8j3eeId+kmdpbDrsUtuH8+fOMGTOGzp07FzU7Gzx4MFWrytFm9s6uA/9KZi6f7klkWPuGeNeSzn/Cummt+c9//oOfnx9r1qzhtddeo0ePHkaXJSyIXa/hf7YnkevZeUyXk6qEDQgODmbVqlV0796d8PBwfH19jS5JWBi7Dfys3HyW7zxD7xZ1aOtV3ehyhCiT4s3OBg4cSPfu3Xn66ael/40okd0u6aw5mELqtWye7NvM6FKEKJMTJ04QEBDA8uXLAQgNDZXOluKO7DbwP9+biN99nvRoVtvoUoS4K3l5ebz11lt06NCBw4cPy85YYTa7XdK5mpVHO6/q0jtEWJXDhw8zefJk9u/fz6OPPsqCBQu47777jC5LWAm7DXwhrFFycjJJSUl8+eWXjBw5UjZYxF0xa0lHKTVYKRWnlDqllHrpNmNGK6VilVIxSqnPyrdMIezXTz/9xOLFiwGKmp2NGjVKwl7ctVIDXynlCCwAhgB+wDillN8tY1oAc4GeWus2wB8roFYh7Mr169d55pln6NWrF++8805RszM3NzeDKxPWypwt/K7AKa11vNY6B1gFBN0yZiqwQGudBqC1vlC+ZZY/LdctFBZs48aNtG3blg8//JCnn35amp2JcmFO4HsBScXuJxc+VlxLoKVSaqdSardSanBJb6SUmqaUilJKRaWmppat4nuktWZp5GkSLmdQ31O+QMLyJCUlMWzYMFxdXYmMjOTDDz/Ew8PD6LKEDTBnp21JC4W3bh47AS2AfkAjYLtSqq3WOv03L9J6KbAUwN/fv9I2sa9m5bJyVwI3svNIuJTBd0d+YVi7+3h2YKvKKkGIUu3fv58uXbrg7e1NREQEvXv3xtXV1eiyhA0xJ/CTAe9i9xsBZ0sYs1trnQucUUrFUfAPwL5yqfIeJKdlMHnFPk6cv46zo8LRQTGjXzOeG9hK+t4Li3Du3Dn+8Ic/sHr1arZu3Urfvn0ZMGCA0WUJG2RO4O8DWiilmgIpwFgg+JYxa4BxwAqlVB0Klnjiy7NQc6w5mELkid8uFUWevEh2Xj6fhXWjR/M6lV2SELeltebf//43s2fPJiMjgzfeeEOanYkKVWrga63zlFIzgQ2AI7Bcax2jlHoViNJaryt8bqBSKhbIB57XWl+qyMJLqJPXvjtGdm4+Ndycix73rlWVt0a2p0V9WQMVlmXs2LF88cUX9OzZk2XLltG6dWujSxI2zqwTr7TWEUDELY/9rdhtDcwp/GWIxMsZXLyezWsj2jL+QblylbBMxZudDR06lN69ezNjxgwcHOy2y4moRDbzUxb1cxoA/k3k4uPCMh0/fpw+ffoQHh4OQEhICDNnzpSwF5XGZn7SohLS8HB1omU9WboRliU3N5c33niDDh06EBsbi7u7u9ElCTtlM7109idcpnPjmnLkjbAohw4dIjQ0lEOHDjFq1Cg+/PBDGjRoYHRZwk7ZROCnZ+Rw4vx1hndoaHQpQvzGuXPnOHfuHF999RWPPfaY0eUIO2cTgX8gsWD9votPLYMrEQJ27NjB4cOHmTFjBoMHD+b06dNUqybXTBbGs4k1/Kif03ByUHT0rmF0KcKOXbt2jZkzZ9K7d2/ef//9omZnEvbCUthG4Cek0carOlVd5NJuwhgbNmygbdu2LFy4kGeeeUaanQmLZBNLOkdTrjDa37v0gUJUgKSkJB5++GGaN2/Ojh075GxZYbGsOvAPJKZxJSOXrNx83KrI1r2oPFpr9u3bR9euXfH29ub777+nV69e0uxMWDSrXdJJupzBYwt/InTFPkwaPFydS3+REOXgl19+YeTIkXTr1o1t27YB0L9/fwl7YfGsdgs/MzcfgOcHtaJ3izr43udpcEXC1mmtWbFiBXPmzCErK4t58+bRs2dPo8sSwmxWG/i/alLbjfaN5OgcUfFGjx7N6tWr6d27N8uWLaNly5ZGlyTEXbG6wL+Smct/dieQkp5pdCnCDuTn56OUwsHBgUceeYSHHnqI6dOnS/8bYZWsLvC3nUjl7Q1xAFR1dsS7VlWDKxK26tixY0yZMoXQ0FCmTp3KxIkTjS5JiHtidYFvMhVcGXHLc/1oWsfN4GqELcrNzWXevHn84x//wN3dnerVqxtdkhDlwuoCX4iKdPDgQSZNmsThw4cZM2YMH3zwAfXq1TO6LCHKhQS+EMWcP3+eixcvsmbNGoKCgowuR4hyJYEv7F5kZCRHjhzh6aefZvDgwZw6dYqqVWXfkLA9VnOowabY8wx6L5I3vz9mdCnCRly9epUZM2bQt29fPvjgg6JmZxL2wlZZTeDvOXOJkxeu0cWnJuMfbIx3TflSirKLiIigTZs2LFmyhDlz5kizM2EXrGpJx9XZkYVPdDG6DGHlkpKSCAoKolWrVqxevZpu3boZXZIQlcJqtvCFuBdaa3bv3g2At7c3Gzdu5MCBAxL2wq5I4Aubd/bsWUaMGEH37t2Lmp0FBATg4uJicGVCVC4JfGGztNYsW7YMPz8/Nm7cyPz586XZmbBrVrWGL8TdGDVqFF9//TV9+/Zl2bJlNG/e3OiShDCUBL6wKcWbnY0YMYKBAwcydepUaXYmBLKkI2zI0aNH6dmzJ+Hh4QBMmDBBOlsKUYx8E4TVy8nJ4ZVXXqFz586cPn2amjVrGl2SEBZJlnSEVdu/fz+TJk3i6NGjBAcH8/7771O3bl2jyxLCIllN4Bd2RRbiNy5dukR6ejrr16/n4YcfNrocISyaVQT+1rgLrNqbSONa1YwuRViALVu2cOTIEWbNmsXAgQM5efKkXEBcCDNY/Br+Z3sSmfJJFI1ru/Fx6ANGlyMMdOXKFaZPn85DDz3EokWLipqdSdgLYR6LDXyTSfPm98f40zdH6N2iDl8+2Z37qkvDNHu1fv16/Pz8WLZsGc899xz79++XZmdC3CWLXNLJys3n2S+i+e7IL4x/sDF/f6QNTo4W+2+TqGBJSUmMHDmS1q1bs2bNGh54QP6nJ0RZWFzgX7qezdR/R3EwKZ0/D/UlrHdTlFJGlyUqmdaaXbt20aNHj6JmZz169JD+N0LcA7M2m5VSg5VScUqpU0qpl+4wbpRSSiul/MtSTE6eiccX7yLm7FUWBndmap/7JeztUHJyMsOHD6dnz55Fzc769esnYS/EPSo18JVSjsACYAjgB4xTSvmVMM4DmAXsKWsxl25kE3/xBi8Mbs2QdveV9W2ElTKZTCxZsgQ/Pz9+/PFH3n33XXr16mV0WULYDHO28LsCp7TW8VrrHGAVUNLVnf8BvAVk3WtRbi6O9/oWwgqNHDmSJ598kgceeICjR48ye/ZsHB3lZ0GI8mJO4HsBScXuJxc+VkQp1Qnw1lp/e6c3UkpNU0pFKaWiUlNT77pYYXvy8vIwmUxAQeB/9NFHbNq0ifvvv9/gyoSwPeYEfkmL6EXnvSqlHID3gGdLeyOt9VKttb/W2r+k09/z8nXhe5pRlbB6hw8fpnv37nz00UcAjB8/nrCwMNlvI0QFMSfwkwHvYvcbAWeL3fcA2gJblVI/Aw8C68qy4zb2l6sANK/nfrcvFVYkOzubl19+mS5dupCQkCC9b4SoJOYclrkPaKGUagqkAGOB4F+f1FpfAer8el8ptRV4TmsddbfFRP18GRcnB9p6Vb/blworsW/fPiZNmkRsbCwTJkzgvffeo3bt2kaXJYRdKDXwtdZ5SqmZwAbAEViutY5RSr0KRGmt15VXMVEJabT3qk4VJ9lRZ6vS0tK4fv06ERERDBkyxOhyhLArZp14pbWOACJueexvtxnbryyFZOXmczTlCpN7NS3Ly4UF27x5M0eOHOGZZ55h4MCBnDhxQtoiCGEAi+lXcDj5Crn5mgd8ahldiign6enpTJ06lcDAQJYsWVLU7EzCXghjWEzg7/v5MgBdfORqRbZg7dq1+Pn5sXz5cl544QVpdiaEBbCYXjr7E9JoVteNmm5y+ry1S0xM5PHHH8fX15d169bh71+mThtCiHJmEVv4JpNmf0Ia/rKcY7W01mzfvh2Axo0bs2nTJvbt2ydhL4QFsYjAP516nSuZuXRpIss51igxMZFhw4bRp0+fomZnffr0kWZnQlgYiwj8xMsZALSs72FwJeJumEwmFi5cSJs2bYiMjOSDDz6QZmdCWDCLWcMHcJAz6q3KY489xtq1axkwYABLly6lSZMmRpckhLgDiwp8Yfny8vJwcHDAwcGBMWPGEBQUxKRJk6T/jRBWwCKWdIR1iI6Oplu3bixduhSAcePGERoaKmEvhJWQwBelysrK4i9/+Qv+/v4kJyfToEEDo0sSQpSBLOmIO9q7dy8hISEcP36ckJAQ3n33XWrVksNnhbBGEvjijq5evUpmZiY//PADgwYNMrocIcQ9kMAXv7Nx40ZiYmKYPXs2/fv3Jy4uTtoiCGEDZA1fFElLSyM0NJRBgwYRHh4uzc6EsDES+AKAr7/+Gj8/P1auXMncuXOJioqSoBfCxsiSjiAxMZGxY8fStm1bIiIi6NSpk9ElCSEqgGzh2ymtdVHfm8aNG7N582b27NkjYS+EDZPAt0MJCQkMGTKEfv36FYV+r169cHZ2NrgyIURFksC3IyaTiX/961+0adOGHTt28OGHH9K7d2+jyxJCVBJZw7cjI0aMYP369QwaNIglS5bg4+NjdElCiEokgW/jcnNzcXR0xMHBgXHjxjFq1CgmTJgg/WsbotAAAAxFSURBVG+EsEOypGPDDhw4QNeuXVm8eDFQ0Oxs4sSJEvZC2CkJfBuUmZnJ3Llz6dq1K+fOncPb29vokoQQFkCWdGzM7t27CQkJ4cSJE0yePJn58+dTs6ZcOlIIIYFvc27cuEFubi7/+9//6N+/v9HlCCEsiAS+Dfjhhx+IiYnh2WefJTAwkOPHj8sFxIUQvyNr+Fbs0qVLhISEMGTIED755BNycnIAJOyFECWSwLdCWmtWr16Nn58fn332GX/5y1/Yt2+fBL0Q4o5kSccKJSYmEhwcTPv27dm4cSMdOnQwuiQhhBWQLXwrobVm8+bNAPj4+LB161Z2794tYS+EMJsEvhU4c+YMAwcOJDAwsKjZWY8ePXBykv+gCSHMJ4FvwfLz8/nnP/9J27Zt2bNnD4sWLZJmZ0KIMpNNRAsWFBTEd999x9ChQ1m8eLGcMSuEuCcS+BameLOzCRMmMG7cOIKDg6X/jRDinpm1pKOUGqyUilNKnVJKvVTC83OUUrFKqcNKqR+VUtJ3twyioqLw9/dn0aJFAIwZM4YnnnhCwl4IUS5KDXyllCOwABgC+AHjlFJ+tww7CPhrrdsDq4G3yrtQW5aZmcmLL75It27dSE1NlT71QogKYc6STlfglNY6HkAptQoIAmJ/HaC13lJs/G5gvDkffvF6Nt9Gn+X4uWvmV2xjdu3aRUhICCdPniQsLIy3336bGjVqGF2WEMIGmRP4XkBSsfvJQLc7jJ8CfF/SE0qpacA0KLhw9hdRSbz1QxwALk4O1HGvYk7NNiUzMxOTycSmTZsIDAw0uhwhhA0zJ/BLWkDWJQ5UajzgD/Qt6Xmt9VJgKYC/v7/Oyy94m4N/HUBVF0dcnR3NqdnqRUREEBMTw/PPP89DDz3EsWPH5ALiQogKZ85O22Sg+PGAjYCztw5SSvUH/gwM11pn300RnlWd7SLsL168yPjx4xk2bBiffvppUbMzCXshRGUwJ/D3AS2UUk2VUi7AWGBd8QFKqU7AEgrC/kL5l2ndtNasWrUKX19fvvjiC15++WX27t0rzc6EEJWq1CUdrXWeUmomsAFwBJZrrWOUUq8CUVrrdcDbgDvwZeEhhIla6+EVWLdVSUxMJCQkhA4dOhAeHk67du2MLkkIYYfMOvFKax0BRNzy2N+K3ZZLK91Ca82PP/5I//798fHxYdu2bTzwwAM4Otr+0pUQwjJJL50KcPr0aQIDAxkwYEBRs7MHH3xQwl4IYSgJ/HKUn5/Pu+++S7t27di/fz9LliyRZmdCCIshvXTK0SOPPML333/Pww8/zKJFi2jUqJHRJQkhRBEJ/HuUk5ODk5MTDg4OTJo0iQkTJjB27FjpfyOEsDiypHMP9u7dS5cuXVi4cCEAo0ePZty4cRL2QgiLJIFfBhkZGTz77LN0796dtLQ0mjVrZnRJQghRKlnSuUs7duwgJCSE+Ph4pk+fzrx586hevbrRZQkhRKkk8O/Srxco2bJlC/369TO6HCGEMJsEvhnWr1/PsWPHeOGFFwgICCA2NlYuIC6EsDqyhn8HqampBAcHM3z4cD7//POiZmcS9kIIaySBXwKtNZ999hm+vr6sXr2aV199lT179kizMyGEVZNN1RIkJiYSGhpKp06dCA8Pp02bNkaXJIQQ90y28AuZTCY2bNgAgI+PD9u3b2fnzp0S9kIImyGBD5w8eZKHHnqIwYMHExkZCUDXrl2l2ZkQwqbYdeDn5eXx9ttv0759ew4dOkR4eLg0OxNC2Cy7XsN/+OGH2bBhA0FBQSxcuJCGDRsaXZIQQlQYuwv87OxsnJ2dcXBwICwsjMmTJ/P4449L/xshhM2zqyWd3bt307lzZxYsWADAqFGjGD16tIS9EMIu2EXg37hxg9mzZ9OjRw+uXbtGixYtjC5JCCEqnc0v6Wzfvp2QkBDOnDnDjBkzePPNN/H09DS6LCGEqHQ2H/h5eXk4Ozuzbds2+vTpY3Q5QghhGJsM/DVr1nDs2DHmzp1LQEAAMTEx0v9GCGH3bGoN//z584wePZpHH32U1atXS7MzIYQoxiYCX2vNypUr8fPzY+3atbz++uvs3r1bmp0JIUQxNrHpm5iYSFhYGP7+/oSHh9O6dWujSxJCCItjtVv4JpOJ77//HihodrZz504iIyMl7IUQ4jasMvBPnDhBv379GDp0KNu2bQPA399fmp0JIcQdGBb4l2/kcDg5/a5ek5eXx7x582jfvj1Hjhzh448/lkMthRDCTIat4aekZ7Lp2AXquFfB3MYGw4YNY+PGjTz22GMsWLCABg0aVGiNQghhS5TW2pAP9vRupU/FROPh6kxVl9svxWRlZeHs7IyjoyNfffUVACNHjqysMoUQwqIopfZrrf3L8lrDlnQUinqerncM+507d9KxY8eiZmcjR46UsBdCiDKyyJ22169fZ9asWfTu3ZusrCx8fX2NLkkIIayexR2Hv23bNkJCQkhMTGTmzJm88cYbuLu7G12WEEJYPYsLfIBq1aqxfft2evbsaXQpQghhMwzbaVvdu7W+knQcgK+//prjx4/zpz/9CYD8/Hw5pl4IIUpQ4TttlVKDlVJxSqlTSqmXSni+ilLqv4XP71FKNTHnfc+dO8eoUaMYOXIk33zzTVGzMwl7IYQof6UGvlLKEVgADAH8gHFKKb9bhk0B0rTWzYH3gHmlvW/OjSv4+vry7bff8uabb/LTTz9JszMhhKhA5mzhdwVOaa3jtdY5wCog6JYxQcAnhbdXA4GqlAvFZqWdp23btkRHR/PSSy/h7Ox8t7ULIYS4C+bstPUCkordTwa63W6M1jpPKXUFqA1cLD5IKTUNmFZ4N3vHjh1HpdkZAHW4Za7smMzFTTIXN8lc3NSqrC80J/BL2lK/dU+vOWPQWi8FlgIopaLKuuPB1shc3CRzcZPMxU0yFzcppaLK+lpzlnSSAe9i9xsBZ283RinlBFQHLpe1KCGEEOXPnMDfB7RQSjVVSrkAY4F1t4xZB4QU3h4FbNZGHe8phBCiRKUu6RSuyc8ENgCOwHKtdYxS6lUgSmu9DggHViqlTlGwZT/WjM9eeg912xqZi5tkLm6SubhJ5uKmMs+FYSdeCSGEqFwW2TxNCCFE+ZPAF0IIO1HhgV9RbRmskRlzMUcpFauUOqyU+lEp5WNEnZWhtLkoNm6UUkorpWz2kDxz5kIpNbrwZyNGKfVZZddYWcz4jjRWSm1RSh0s/J4MNaLOiqaUWq6UuqCUOnqb55VS6oPCeTqslOps1htrrSvsFwU7eU8D9wMuQDTgd8uYGcDiwttjgf9WZE1G/TJzLgKAaoW3n7LnuSgc5wFEArsBf6PrNvDnogVwEKhZeL+e0XUbOBdLgacKb/sBPxtddwXNRR+gM3D0Ns8PBb6n4ByoB4E95rxvRW/hV0hbBitV6lxorbdorTMK7+6m4JwHW2TOzwXAP4C3gKzKLK6SmTMXU4EFWus0AK31hUqusbKYMxca8Cy8XZ3fnxNkE7TWkdz5XKYg4N+6wG6ghlLqvtLet6IDv6S2DF63G6O1zgN+bctga8yZi+KmUPAvuC0qdS6UUp0Ab631t5VZmAHM+bloCbRUSu1USu1WSg2utOoqlzlz8XdgvFIqGYgA/lA5pVmcu80ToOIvgFJubRlsgNl/TqXUeMAf6FuhFRnnjnOhlHKgoOvqpMoqyEDm/Fw4UbCs04+C//VtV0q11VqnV3Btlc2cuRgHrNBav6OU6k7B+T9ttdamii/PopQpNyt6C1/aMtxkzlyglOoP/BkYrrXOrqTaKltpc+EBtAW2KqV+pmCNcp2N7rg19zuyVmudq7U+A8RR8A+ArTFnLqYAXwBorXcBrhQ0VrM3ZuXJrSo68KUtw02lzkXhMsYSCsLeVtdpoZS50Fpf0VrX0Vo30Vo3oWB/xnCtdZmbRlkwc74jayjYoY9Sqg4FSzzxlVpl5TBnLhKBQACllC8FgZ9aqVVahnXAxMKjdR4ErmitfyntRRW6pKMrri2D1TFzLt4G3IEvC/dbJ2qthxtWdAUxcy7sgplzsQEYqJSKBfKB57XWl4yrumKYORfPAh8ppWZTsIQxyRY3EJVSn1OwhFencH/Fy4AzgNZ6MQX7L4YCp4AMINSs97XBuRJCCFECOdNWCCHshAS+EELYCQl8IYSwExL4QghhJyTwhRDCTkjgCyGEnZDAF0IIO/H/LJzStkYDv/EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the ROC graph\n",
    "fpr,tpr,thresholds = metrics.roc_curve(Y_te,pred_proba[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.axis([0,1,0,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Accuracy = 0.783 AUC = 0.825\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Age*Class</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Age_1</th>\n",
       "      <th>Age_2</th>\n",
       "      <th>Age_3</th>\n",
       "      <th>Age_4</th>\n",
       "      <th>Fare_1</th>\n",
       "      <th>Fare_2</th>\n",
       "      <th>Fare_3</th>\n",
       "      <th>Embarked_1</th>\n",
       "      <th>Embarked_2</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "      <th>Title_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  IsAlone  Age*Class  Pclass_2  Pclass_3  Age_1  Age_2  Age_3  Age_4  \\\n",
       "0      0        0          3         0         1      1      0      0      0   \n",
       "1      1        0          2         0         0      0      1      0      0   \n",
       "2      1        1          3         0         1      1      0      0      0   \n",
       "3      1        0          2         0         0      0      1      0      0   \n",
       "4      0        1          6         0         1      0      1      0      0   \n",
       "..   ...      ...        ...       ...       ...    ...    ...    ...    ...   \n",
       "413    0        1          3         0         1      1      0      0      0   \n",
       "414    1        1          2         0         0      0      1      0      0   \n",
       "415    0        1          6         0         1      0      1      0      0   \n",
       "416    0        1          3         0         1      1      0      0      0   \n",
       "417    0        0          3         0         1      1      0      0      0   \n",
       "\n",
       "     Fare_1  Fare_2  Fare_3  Embarked_1  Embarked_2  Title_2  Title_3  \\\n",
       "0         0       0       0           0           0        0        0   \n",
       "1         0       0       1           1           0        0        1   \n",
       "2         1       0       0           0           0        1        0   \n",
       "3         0       0       1           0           0        0        1   \n",
       "4         1       0       0           0           0        0        0   \n",
       "..      ...     ...     ...         ...         ...      ...      ...   \n",
       "413       1       0       0           0           0        0        0   \n",
       "414       0       0       1           1           0        0        0   \n",
       "415       0       0       0           0           0        0        0   \n",
       "416       1       0       0           0           0        0        0   \n",
       "417       0       1       0           1           0        0        0   \n",
       "\n",
       "     Title_4  Title_5  \n",
       "0          0        0  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "..       ...      ...  \n",
       "413        0        0  \n",
       "414        0        1  \n",
       "415        0        0  \n",
       "416        0        0  \n",
       "417        1        0  \n",
       "\n",
       "[1309 rows x 18 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use an ensemble model, we combine the non-dummy and dummy variables apart\n",
    "pd.get_dummies(combine, columns=dummy_columns, drop_first=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.base\n",
    "class my_ensemble_model(sklearn.base.BaseEstimator):\n",
    "\n",
    "    def fit(self, X_train, Y_train, hold=False, **param):\n",
    "        assert(\"split_pos\" in param)\n",
    "        \n",
    "        self.models = list(model_dict.values())\n",
    "        if not hold:\n",
    "            for model in self.models:\n",
    "                model.fit(X_train, Y_train)\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        pred_list = np.vstack([model.predict(X_test) for model in self.models])\n",
    "        #mod = np.squeeze((pred_list.mean(axis=0) > 0.5).astype(int))\n",
    "        return pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    1\n",
      "890    0\n",
      "Length: 891, dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8282828282828283"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getScore(my_ensemble_model(), X_train, Y_train)\n",
    "#getScore(my_ensemble_model(), X_train_dummy, Y_train)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for model_key,model in model_dict.items():\n",
    "    model.fit(X_train,Y_train)\n",
    "    result[model_key] = model.predict(X_train)\n",
    "\n",
    "for model_key,model in model_dict_dummy.items():\n",
    "    model.fit(X_train_dummy,Y_train)\n",
    "    result[model_key] = model.predict(X_train_dummy)\n",
    "\n",
    "ensemble_res = np.round(result.mean(axis=1)).astype(int)\n",
    "print(ensemble_res)\n",
    "metrics.accuracy_score(Y_train,ensemble_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy rate of the ensemble_model is 0.810."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class zero_model(sklearn.base.BaseEstimator):\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        x_len = X_test.shape[0]\n",
    "        return np.zeros(x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_dict['Stochastic Gradient Descent']\n",
    "\n",
    "model_dict['zero']=zero_model()\n",
    "getScore(my_ensemble_model(), X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy rate of the new ensemble_model is 0.806."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clear the models and fit new ones with\n",
    "# hyperparamter selection.\n",
    "for key in list(model_dict.keys()):\n",
    "    del model_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First center and normalize the data as follows.\n",
    "# Here are the first five lines of the processed data\n",
    "X_train_scaled = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validator\n",
    "cv = model_selection.KFold(n_splits=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# KNN\n",
    "knn_grid = {\"n_neighbors\" : np.arange(1, 15), \"p\": [1, 2], } \n",
    "knn = model_selection.GridSearchCV(KNeighborsClassifier(), knn_grid,\n",
    "          scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "knn.fit(X_train_scaled, Y_train)\n",
    "print(knn.score(X_train_scaled, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Logistic Regression\n",
    "logreg = linear_model.LogisticRegressionCV(cv=cv, max_iter=1000, random_state=1)\n",
    "logreg.fit(X_train_scaled, Y_train)\n",
    "print(logreg.score(X_train_scaled, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# SVC\n",
    "svc_param_grid = {\n",
    "    \"kernel\" : ['linear', 'rbf', 'poly'],\n",
    "    \"C\" : np.logspace(-3, 1, 5),\n",
    "    \"gamma\" : [\"auto\", \"scale\"],\n",
    "    \"degree\" : np.arange(5)\n",
    "}\n",
    "\n",
    "svc = model_selection.GridSearchCV(SVC(random_state=1), svc_param_grid,\n",
    "        scoring=\"accuracy\", cv=cv, n_jobs=-1)\n",
    "svc.fit(X_train_scaled, Y_train)\n",
    "\n",
    "print(svc.score(X_train_scaled, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost has to be manually tuned\n",
    "# We split the training data to get a validation set.\n",
    "X_tr, X_val, Y_tr, Y_val = model_selection.train_test_split(\n",
    "    X_train_scaled, Y_train, test_size=0.3)\n",
    "eval_set = ((X_tr, Y_tr), (X_val, Y_val))\n",
    "eval_metric = [\"auc\", \"error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Using the validation set we tune the hyperparameters of XGBClassifier.\n",
    "# To avoid overfitting and wasting computation, we stop after 200 trees.\n",
    "xgb = XGBClassifier(scale_pos_weight=1,\n",
    "                  learning_rate=0.01,  \n",
    "                  colsample_bytree=0.8,\n",
    "                  subsample=0.8,\n",
    "                  objective='binary:logistic', \n",
    "                  n_estimators=200, \n",
    "                  reg_alpha=0.3,\n",
    "                  max_depth=3, \n",
    "                  gamma=1,\n",
    "                  random_state=1\n",
    "                )\n",
    "xgb.fit(X_tr, Y_tr, eval_metric=eval_metric, eval_set=eval_set,\n",
    "          verbose=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After that we use the hyperparameters and fit on the whole training set.\n",
    "xgb.fit(X_train_scaled, Y_train)\n",
    "print(xgb.score(X_train_scaled, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train_scaled, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ensemble these three methods, and do not refit.\n",
    "model_dict = {\n",
    "    \"knn\": knn,\n",
    "    \"xgb\": xgb,\n",
    "    \"logreg\": logreg,\n",
    "    \"svc\": svc,\n",
    "    \"random forest\": rfc\n",
    "}\n",
    "model = my_ensemble_model().fit(X_train_scaled, Y_train, hold=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now scale the test data along with the training data.\n",
    "# Here are the first five row of the transformed test data.\n",
    "X_combine = pd.concat([X_train, X_test])\n",
    "X_test_scaled = (X_test - X_combine.mean(axis=0)) / X_combine.std(axis=0)\n",
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last we use our ensemble model to make predictions.\n",
    "pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assemble the predictions in order to make submission to kaggle.\n",
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"PassengerID\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": pred\n",
    "    }\n",
    ")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conslusion: With the latest submission to Kaggle under team name \"miaonima\" at 12:10 pm 11/19/2019, the score for public test is 0.79904. "
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
