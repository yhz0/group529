{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from sklearn import model_selection, linear_model, metrics, pipeline, preprocessing\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and separate the id's\n",
    "X_data  = pd.read_hdf(\"cat.hdf5\", \"train\")\n",
    "y_data  = pd.read_hdf(\"cat.hdf5\", \"train_target\")\n",
    "X_test  = pd.read_hdf(\"cat.hdf5\", \"test\")\n",
    "\n",
    "# Store data ID\n",
    "data_id = X_data.loc[:, \"id\"]\n",
    "test_id = X_test.loc[:, \"id\"]\n",
    "\n",
    "X_data.drop(columns=\"id\", inplace=True)\n",
    "X_test.drop(columns=\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dummy data and separate the id's\n",
    "X_data_dmy  = pd.read_hdf(\"cat.hdf5\", \"train_dmy\")\n",
    "X_test_dmy  = pd.read_hdf(\"cat.hdf5\", \"test_dmy\")\n",
    "\n",
    "X_data_dmy.drop(columns=\"id\", inplace=True)\n",
    "X_test_dmy.drop(columns=\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data with labels into training and validation.\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X_data, y_data, test_size=0.3)\n",
    "\n",
    "X_train_dmy, X_val_dmy, y_train_dmy, y_val_dmy = \\\n",
    "    model_selection.train_test_split(X_data_dmy, y_data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210000, 40) (210000,) (90000, 40) (90000,) (200000, 40)\n",
      "(210000, 275) (210000,) (90000, 275) (90000,) (200000, 275)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape)\n",
    "print(X_train_dmy.shape, y_train_dmy.shape, X_val_dmy.shape, y_val_dmy.shape, X_test_dmy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitic Regression as baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", linear_model.LogisticRegressionCV(\n",
    "            solver=\"lbfgs\", max_iter=2000, cv=5, n_jobs=-1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "logistic.fit(X_train_dmy, y_train_dmy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(model):\n",
    "    y_val_pred = model.predict_proba(X_val_dmy)[:, 1]\n",
    "    val_score = metrics.roc_auc_score(y_val_dmy, y_val_pred)\n",
    "\n",
    "    y_train_pred = model.predict_proba(X_train_dmy)[:, 1]\n",
    "    train_score = metrics.roc_auc_score(y_train_dmy, y_train_pred)\n",
    "\n",
    "    return (train_score, val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7660802466134071, 0.7640294373295451)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now use XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do not use GridSearchCV:\n",
    "# See https://github.com/dmlc/xgboost/issues/2819\n",
    "# Instead we implement our own grid search.\n",
    "\n",
    "from collections.abc import Iterable\n",
    "import itertools\n",
    "\n",
    "# Takes a parameter grid similar to the format in\n",
    "# sklearn GridSearchCV and returns a list of names every time.\n",
    "def get_grid_iter(param_grid):\n",
    "    names = []\n",
    "    values = []\n",
    "    \n",
    "    for param_name, param_values in param_grid.items():\n",
    "        names.append(param_name)\n",
    "        \n",
    "        if isinstance(param_values, list):\n",
    "            values.append(list(param_values))\n",
    "        else:\n",
    "            values.append(list([param_values]))\n",
    "    \n",
    "    it = (dict(zip(names, param)) for param in itertools.product(*values))\n",
    "    item_cnt = np.prod(np.array([len(v) for v in values]))\n",
    "    return it, item_cnt\n",
    "\n",
    "# Similar to GridSearchCV\n",
    "def hyper_opt(model_base, param_grid, metric, X_train, y_train, X_val, y_val, bin_prob, verbose=False):\n",
    "    best_param = None\n",
    "    best_param_id = -1\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    it, item_cnt = get_grid_iter(param_grid)\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for param in it:\n",
    "        \n",
    "        model = model_base(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        if bin_prob:\n",
    "            y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "            y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        train_score = metric(y_train, y_train_pred)\n",
    "        val_score = metric(y_val, y_val_pred)\n",
    "        \n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_param = param\n",
    "            best_param_id = step\n",
    "        \n",
    "        step += 1\n",
    "        if verbose:\n",
    "            print(\"[%d/%d] train:%f test:%f best:%f id:%d\" %\n",
    "                (step, item_cnt, train_score, val_score, best_score, best_param_id))\n",
    "            \n",
    "    return best_score, best_param, best_param_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [500, 1000, 1500, 2500, 3000],\n",
    "    'max_depth':[1, 2, 3, 4, 5],\n",
    "    'objective':'binary:logistic',\n",
    "    'subsample':[0.6, 0.8, 1], \n",
    "    'colsample_bytree':[0.6, 0.8, 1],\n",
    "    'learning_rate':[0.001, 0.01, 0.1],\n",
    "    'tree_method':'gpu_hist',\n",
    "    'evalmetric':'auc'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#score, param, param_id = hyper_opt(XGBClassifier, xgb_param_grid, metrics.roc_auc_score,\n",
    "#          X_train, y_train, X_val, y_val,\n",
    "#          bin_prob=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 3000,\n",
       " 'max_depth': 2,\n",
       " 'objective': 'binary:logistic',\n",
       " 'subsample': 1,\n",
       " 'colsample_bytree': 0.6,\n",
       " 'learning_rate': 0.1,\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'evalmetric': 'auc'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_id = 587\n",
    "best_param = list(get_grid_iter(xgb_param_grid)[0])[param_id]\n",
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, evalmetric='auc',\n",
       "              gamma=0, gpu_id=-1, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=2, min_child_weight=1, missing=None, n_estimators=3000,\n",
       "              n_jobs=1, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='gpu_hist', verbosity=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb  = XGBClassifier(**best_param)\n",
    "xgb.fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_proba   = logistic.predict_proba(X_test)[:, 1]\n",
    "xgb_proba        = xgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24827955, 0.5188349 , 0.18679945, ..., 0.18501229, 0.45643572,\n",
       "       0.24577431])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_score   = logistic.score(X_val,y_val)\n",
    "xgb_score        = xgb.score(X_val,y_val)\n",
    "\n",
    "logistic_weight  = logistic_score/(logistic_score + xgb_score)\n",
    "xgb_weight       = xgb_score/(logistic_score + xgb_score)\n",
    "\n",
    "target           = logistic_proba*logistic_weight + xgb_proba*xgb_weight\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": test_id,\n",
    "        \"target\": target\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check X_train AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_roc: 0.765422,  xgb_roc: 0.788937,  target_roc: 0.780851,\n"
     ]
    }
   ],
   "source": [
    "logistic_proba   = logistic.predict_proba(X_data)[:, 1]\n",
    "xgb_proba        = xgb.predict_proba(X_data)[:,1]\n",
    "\n",
    "target           = logistic_proba*logistic_weight + xgb_proba*xgb_weight\n",
    "logistic_roc     = metrics.roc_auc_score(y_data, logistic_proba)\n",
    "xgb_roc          = metrics.roc_auc_score(y_data, xgb_proba)\n",
    "target_roc       = metrics.roc_auc_score(y_data, target)\n",
    "\n",
    "print('logistic_roc: %f,  xgb_roc: %f,  target_roc: %f,'%(logistic_roc, xgb_roc, target_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From above we know that Logistics Regression is shit. Kick it off!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_roc(model, X_train, y_train, metric=metrics.roc_auc_score):\n",
    "    #cv = model_selection.KFold(n_splits=5)\n",
    "    #score = model_selection.cross_va√ül_score(model,\n",
    "            #X_train,y_train,scoring=metrics.make_scorer(metric), cv=cv)\n",
    "    #return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc(model,X_train,y_train,X_val,y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "    val_score = metrics.roc_auc_score(y_val, y_val_pred)\n",
    "\n",
    "    y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "    train_score = metrics.roc_auc_score(y_train, y_train_pred)\n",
    "\n",
    "    return (train_score, val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", SVC(gamma='auto',probability=True))\n",
    "        ])\n",
    "\n",
    "knn = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", KNeighborsClassifier(n_neighbors = 3,n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "logistic = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", LogisticRegression(solver='lbfgs',n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "rf = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", RandomForestClassifier(n_estimators=100,n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "nb = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", GaussianNB())\n",
    "        ])\n",
    "\n",
    "perceptron = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", Perceptron(n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "sgd = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", SGDClassifier(n_jobs=-1))\n",
    "        ])\n",
    "\n",
    "lsvc = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", LinearSVC(max_iter=10000))\n",
    "        ])\n",
    "\n",
    "decision_tree = pipeline.Pipeline([\n",
    "        (\"min_max_scaler\", preprocessing.MinMaxScaler()),\n",
    "        (\"logistic_classifier\", DecisionTreeClassifier())\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_list = []\n",
    "val_score_list   = []\n",
    "\n",
    "model_dict = {\n",
    "             'Random Forest':rf,\n",
    "             'Decision Tree':decision_tree\n",
    "             }\n",
    "\n",
    "model_dict_dmy = {\n",
    "             'Support Vector Machines':svc,\n",
    "             'KNN':knn,\n",
    "             'Logistic Regression':logistic,\n",
    "             'Naive Bayes':nb,\n",
    "             'Perceptron':perceptron,\n",
    "             'Stochastic Gradient Descent':sgd,\n",
    "             'Linear SVC':lsvc,\n",
    "             }\n",
    "for model_name,model in model_dict.items():\n",
    "    train_score, val_score = get_roc(model,X_train,y_train,X_val,y_val)\n",
    "    train_score_list.append(train_score)\n",
    "    val_score_list.append(val_score)\n",
    "    \n",
    "for model_name,model in model_dict_dmy.items():\n",
    "    train_score, val_score = get_roc(model,X_train_dmy,y_train_dmy,X_val_dmy,y_val_dmy)\n",
    "    train_score_list.append(train_score)\n",
    "    val_score_list.append(val_score)\n",
    "    \n",
    "\n",
    "score_pd = pd.DataFrame({'model':list(model_dict.keys()),'Train score':train_score_list, \n",
    "                         'Validation score':val_score_list}) \n",
    "score_pd.sort_values(by='Validation score', ascending=False)\n",
    "score_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
